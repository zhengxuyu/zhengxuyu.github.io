@article{beck_tutorial_2025,
	title = {A Tutorial on Meta-Reinforcement Learning},
	volume = {18},
	issn = {1935-8237, 1935-8245},
	url = {http://arxiv.org/abs/2301.08028},
	doi = {10.1561/2200000080},
	abstract = {While deep reinforcement learning ({RL}) has fueled multiple high-profile successes in machine learning, it is held back from more widespread adoption by its often poor data efficiency and the limited generality of the policies it produces. A promising approach for alleviating these limitations is to cast the development of better {RL} algorithms as a machine learning problem itself in a process called meta-{RL}. Meta-{RL} is most commonly studied in a problem setting where, given a distribution of tasks, the goal is to learn a policy that is capable of adapting to any new task from the task distribution with as little data as possible. In this survey, we describe the meta-{RL} problem setting in detail as well as its major variations. We discuss how, at a high level, meta-{RL} research can be clustered based on the presence of a task distribution and the learning budget available for each individual task. Using these clusters, we then survey meta-{RL} algorithms and applications. We conclude by presenting the open problems on the path to making meta-{RL} part of the standard toolbox for a deep {RL} practitioner.},
	pages = {224--384},
	number = {2},
	journaltitle = {Foundations and TrendsÂ® in Machine Learning},
	shortjournal = {{FNT} in Machine Learning},
	author = {Beck, Jacob and Vuorio, Risto and Liu, Evan Zheran and Xiong, Zheng and Zintgraf, Luisa and Finn, Chelsea and Whiteson, Shimon},
	urldate = {2025-07-29},
	date = {2025},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2301.08028 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@thesis{schmidhuber_evolutionary_1987,
	title = {Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook},
	author = {Schmidhuber, J{\"u}rgen},
	institution = {Institut f{\"u}r Informatik, Technische Universit{\"a}t M{\"u}nchen},
	date = {1987},
	langid = {english},
}

@incollection{thrun_lifelong_1998,
	title = {Lifelong learning algorithms},
	author = {Thrun, Sebastian and Pratt, Lorien},
	booktitle = {Learning to learn},
	pages = {181--209},
	date = {1998},
	publisher = {Springer},
	langid = {english},
}

@inproceedings{finn_model_2017,
	title = {Model-agnostic meta-learning for fast adaptation of deep networks},
	author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	booktitle = {International conference on machine learning},
	pages = {1126--1135},
	date = {2017},
	organization = {PMLR},
	langid = {english},
}

@article{wang_learning_2016,
	title = {Learning to reinforcement learn},
	author = {Wang, Jane X. and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z. and Munos, R{\'e}mi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
	journaltitle = {arXiv preprint arXiv:1611.05763},
	date = {2016},
	langid = {english},
} 